{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca87aeac",
   "metadata": {},
   "source": [
    "### The set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7a7182",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "save_timestamp = time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "\n",
    "#makes the output nicer\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 44em; }</style>\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe20923",
   "metadata": {},
   "source": [
    "### Initating our dataset\n",
    "\n",
    "Here we'll load our base data set, and do some necessary transformations to get the data we want in the way we want it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f229b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading the dataset initially\n",
    "df = pd.read_excel('Global Solar Power Tracker - main V1.xlsx', 'Europe')\n",
    "\n",
    "\n",
    "df = df.loc[(df['Location accuracy']=='exact') & (df['Technology Type'] != 'Solar Thermal')&(df['Status']=='operating')]\n",
    "df = df[['Country', 'Project Name', 'Capacity (MW)', 'Latitude', 'Longitude']].reset_index(drop=True)\n",
    "df['Capacity (MW)'] = pd.to_numeric(df['Capacity (MW)'])\n",
    "\n",
    "#Smaller plants are harder to identify-- let's start with a 5MW threshold\n",
    "df_10MW = df.loc[df['Capacity (MW)']>10].reset_index(drop=True)\n",
    "df_5MW = df.loc[df['Capacity (MW)']>5].reset_index(drop=True)\n",
    "df_5MW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22ef42",
   "metadata": {},
   "source": [
    "Let's take a look at what our dataset looks like now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d2f3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_5MW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685479e",
   "metadata": {},
   "source": [
    "Here we're just creating some subsets of the data to make the labelling task a little easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ccdad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subsetdf = df_5MW.reset_index().values\n",
    "batch1 = subsetdf[0:300]\n",
    "batch2 = subsetdf[301:600]\n",
    "batch3 = subsetdf[601:900]\n",
    "batch4 = subsetdf[901:1200]\n",
    "batch5 = subsetdf[1201:1500]\n",
    "batch6 = subsetdf[1501:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6129b3",
   "metadata": {},
   "source": [
    "Since we won't be doing all the labelling in one go, we want a way to keep track of which plants we've already labelled. We do that later on by creating a document that keeps track of whats been labelled. We'll load that document here and do some manipulation to make it easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f84f51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#imagess = 'ImageFetching_2023-05-24.xlsx'\n",
    "#imagess = 'ImageFetching_2023-05-26_1029.xlsx'\n",
    "#imagess = 'ImageFetching_2023-05-29_1857.xlsx'\n",
    "imagess = 'ImageFetching_2023-05-31_1417.xlsx'\n",
    "previmages_df = pd.read_excel(imagess, index_col=0)\n",
    "previmages = previmages_df[['Result']].reset_index().values.tolist()\n",
    "previmages = [tuple(l) for l in previmages]\n",
    "previmages_dict=dict(previmages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf8481",
   "metadata": {},
   "source": [
    "## Initating the labeling process\n",
    "\n",
    "We're using BingMaps to pull aerial images of all the solar fields in our dataset.\n",
    "\n",
    "This for loop will:\n",
    "1. Skip any rows of the dataframe that have already been labelled\n",
    "2. Take the lat/lon coordinates of each solar plant in our dataframe subset and pass them into the BingMaps API to retrieve an aerial image of these coordinates\n",
    "3. Show the resulting image and prompt the user to label it as having a solar field or not\n",
    "4. Save the image to our local directory as well as to that file keeping track of how we're labelling each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e874d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "save_directory = \"BingMaps Test Images\"\n",
    "plt.ion()\n",
    "\n",
    "images = {}\n",
    "for i,country, projname, cap, lat, lon in batch4:\n",
    "    if i in previmages_df.index:\n",
    "        pass\n",
    "    else:\n",
    "        save_directory = \"BingMaps Test Images\"\n",
    "        api_key = 'AmsQbXtxrmBgb0YK_x1LDIGMdCtq9YgTLfiKn76-I-QU2yGZneThmpzh4MTHT32x'\n",
    "        zoom_level = 18\n",
    "        map_width = 600\n",
    "        map_height = 600\n",
    "\n",
    "        #lat = df.loc[0]['Latitude']\n",
    "        #lon = df.loc[0]['Longitude']\n",
    "\n",
    "        api_url = f'https://dev.virtualearth.net/REST/v1/Imagery/Map/Aerial/{lat},{lon}/{zoom_level}?mapsize={map_width},{map_height}&key={api_key}'\n",
    "\n",
    "        response = requests.get(api_url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            #images[i] = image\n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            #plt.pause(0.01)\n",
    "\n",
    "            user_input = input('Is there a solar field in this image? (Y/N):')\n",
    "            if user_input.upper() == 'Y':\n",
    "                filename = f\"positive_{country}_{projname}.jpg\"\n",
    "                image.save(os.path.join(save_directory, filename))\n",
    "                images[i] = filename\n",
    "\n",
    "            elif user_input.upper()=='N':\n",
    "                images[i] = 'No solar field found'\n",
    "                filename = f\"negative_{country}_{projname}.jpg\"\n",
    "                image.save(os.path.join(save_directory, filename))\n",
    "                images[i] = filename\n",
    "\n",
    "            #If the image isn't totally clear as yes or no, user can in put \"eh\" to manually double check and decide later on\n",
    "            elif user_input.upper()=='EH':\n",
    "                filename = f\"DOUBLECHECK_{country}_{projname}.jpg\"\n",
    "                image.save(os.path.join(save_directory, filename))\n",
    "                images[i] = filename\n",
    "            #This is useful as there are sometimes duplicates in the dataframe, or if for whatever reason we don't want to \n",
    "                #use a certain image\n",
    "            elif user_input.upper()==\"SKIP\":\n",
    "                images[i] = 'Skipped'\n",
    "                \n",
    "            #This is useful if we want to stop and take a break before the batch runs through. \n",
    "                #(This part is pretty boring, after all.)\n",
    "            elif user_input.upper()=='DONE':\n",
    "                images = {**previmages_dict, **images}\n",
    "                imagesdf = pd.DataFrame.from_dict(images, orient='index', columns=['Result'])\n",
    "                imagesdf_merged=pd.merge(imagesdf, df_5MW, left_index=True, right_index=True)\n",
    "                imagesdf_merged.to_excel(f'ImageFetching_{save_timestamp}.xlsx')\n",
    "                print(f'Ended on {projname} in {country}')\n",
    "                break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            #plt.close()\n",
    "        else:\n",
    "            images[i] = 'Failed to retrieve image'\n",
    "            print('Failed to retrieve image')\n",
    "            \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852f440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##add the newly labelled images to the dictionary containing the previously labelled images\n",
    "images = {**previmages_dict, **images}\n",
    "imagesdf = pd.DataFrame.from_dict(images, orient='index', columns=['Result'])\n",
    "imagesdf_merged=pd.merge(imagesdf, df_5MW, left_index=True, right_index=True)\n",
    "\n",
    "#export to excel\n",
    "imagesdf_merged.to_excel(f'ImageFetching_{save_timestamp}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2a10e",
   "metadata": {},
   "source": [
    "### Extra data, if needed\n",
    "\n",
    "If we need more negative samples, we can repeat the process except with a susbet of the original dataframe where the lat/lon have been already marked as <i> not </i> containing solar fields. This way we can get some random landscape images to serve as negative samples in our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read and manipulate the original dataset to pull entries without exact location coordinates\n",
    "df_neg = pd.read_excel('Global Solar Power Tracker - main V1.xlsx', 'Europe')\n",
    "df_neg = df_neg.loc[(df_neg['Location accuracy']=='approximate') & (df_neg['Technology Type'] != 'Solar Thermal')&(df_neg['Status']=='operating')]\n",
    "df_neg = df_neg[['Country', 'Project Name', 'Capacity (MW)', 'Latitude', 'Longitude']].reset_index(drop=True)\n",
    "df_neg['Capacity (MW)'] = pd.to_numeric(df_neg['Capacity (MW)'])\n",
    "\n",
    "df_neg_5MW = df_neg.loc[df_neg['Capacity (MW)']>5].reset_index(drop=True)\n",
    "df_neg_5MW = df_neg_5MW.reset_index().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148fe281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat the labelling process with the negative dataframe\n",
    "save_directory = \"BingMaps Test Images\"\n",
    "plt.ion()\n",
    "\n",
    "neg_images = {}\n",
    "for i,country, projname, cap, lat, lon in df_neg_5MW:\n",
    "    save_directory = \"BingMaps Test Images\"\n",
    "    api_key = 'AmsQbXtxrmBgb0YK_x1LDIGMdCtq9YgTLfiKn76-I-QU2yGZneThmpzh4MTHT32x'\n",
    "    zoom_level = 18\n",
    "    map_width = 600\n",
    "    map_height = 600\n",
    "\n",
    "    #lat = df.loc[0]['Latitude']\n",
    "    #lon = df.loc[0]['Longitude']\n",
    "\n",
    "    api_url = f'https://dev.virtualearth.net/REST/v1/Imagery/Map/Aerial/{lat},{lon}/{zoom_level}?mapsize={map_width},{map_height}&key={api_key}'\n",
    "\n",
    "    response = requests.get(api_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        #images[i] = image\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        #plt.pause(0.01)\n",
    "\n",
    "        user_input = input('Is there a solar field in this image? (Y/N):')\n",
    "        if user_input.upper() == 'Y':\n",
    "            filename = f\"positive_{country}_{projname}.jpg\"\n",
    "            image.save(os.path.join(save_directory, filename))\n",
    "            images[i] = filename\n",
    "\n",
    "        elif user_input.upper()=='N':\n",
    "            images[i] = 'No solar field found'\n",
    "            filename = f\"negative_{country}_{projname}.jpg\"\n",
    "            image.save(os.path.join(save_directory, filename))\n",
    "            images[i] = filename\n",
    "\n",
    "        elif user_input.upper()=='EH':\n",
    "            filename = f\"DOUBLECHECK_{country}_{projname}.jpg\"\n",
    "            image.save(os.path.join(save_directory, filename))\n",
    "            images[i] = filename\n",
    "        elif user_input.upper()==\"SKIP\":\n",
    "            images[i] = 'Skipped'\n",
    "        elif user_input.upper()=='DONE':\n",
    "            #images = {**previmages_dict, **images}\n",
    "            imagesdf = pd.DataFrame.from_dict(images, orient='index', columns=['Result'])\n",
    "            imagesdf_merged=pd.merge(imagesdf, df_5MW, left_index=True, right_index=True)\n",
    "            imagesdf_merged.to_excel(f'NEGATIVES_ImageFetching_{save_timestamp}.xlsx')\n",
    "            print(f'Ended on {projname} in {country}')\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        #plt.close()\n",
    "    else:\n",
    "        images[i] = 'Failed to retrieve image'\n",
    "        print('Failed to retrieve image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e4f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
